# 幻觉处理

## 什么是 AI 幻觉

AI 幻觉是指 AI 模型生成看似合理但实际上是错误的内容。在编程领域，幻觉表现为：生成不存在的 API、编造不准确的文档、写出有逻辑错误的代码等。

理解幻觉的本质、识别幻觉、应对幻觉是 Vibe Coding 的重要技能。

## 幻觉产生的原因

### 知识不完整

AI 模型的知识来自训练数据，可能对某些新出的技术、较小的库、不常见的用法了解不准确。

### 模式匹配偏差

AI 倾向于生成"看起来正确"的代码，而不一定是"确实正确"的代码。它可能从不同来源的模式中组合出看似合理但实际错误的代码。

### 上下文误解

当上下文信息不完整或模糊时，AI 可能基于错误的理解生成代码。

### 过度自信

AI 不会像人类那样对自己不确定的内容表示怀疑，而是会给出看似确定的回答。

## 识别幻觉的方法

### 代码验证

最直接的方法是验证代码：尝试运行代码，看是否有错误。检查 API 是否存在且用法正确。验证逻辑是否符合预期。

### 交叉验证

使用多种方式验证同一信息：在文档中查找相关内容。让 AI 提供官方文档链接。搜索互联网确认信息的准确性。

### 合理性检查

对 AI 的回答进行合理性检查：这个 API 真的存在吗？这个用法符合库的官方文档吗？这个逻辑是否有明显的漏洞？

### 专家审核

对重要的代码，请有经验的人审核。或者让另一个 AI 进行交叉审核。

## 常见幻觉类型

### API 幻觉

编造不存在的 API 或错误的 API 用法。

示例：AI 声称某个库有一个 getData 方法，但实际不存在或参数不同。

### 版本幻觉

给出过时的或未来的 API 版本信息。

示例：描述了一个将在未来版本中移除的 API，或者给出一个不存在的版本号。

### 文档幻觉

编造文档内容或不存在的方法。

示例：声称某个参数支持某个值，但文档中并没有说明。

### 逻辑幻觉

生成有逻辑错误或边界情况未处理的代码。

示例：循环条件写错、变量作用域错误、异常处理不当。

## 应对幻觉的策略

### 提供准确上下文

给 AI 提供准确的上下文信息：使用的技术栈和版本。项目的具体需求和约束。已知的正确做法和已有代码。

### 限定范围

限定 AI 生成代码的范围：明确告诉 AI 只使用哪些库。指定代码必须遵循的规范。要求 AI 解释代码的每部分作用。

### 分步验证

不要一次性生成大量代码，而是分步验证：先生成框架，确认结构正确。逐步添加功能，每步都验证。最后整合和优化。

### 要求解释

让 AI 解释生成的代码：这段代码为什么这样写？这个 API 的具体用法是什么？处理了哪些边界情况？

### 兜底方案

为可能的错误准备兜底方案：代码运行失败时的备选方案。AI 回答不可信时的人工介入机制。关键功能的人工复核流程。

## 特定场景的处理

### 新技术/库

使用不熟悉的库时更容易遇到幻觉。应对方法：先阅读官方文档建立基准认知。询问 AI 时引用官方文档。让 AI 提供可验证的代码示例。

### 复杂逻辑

处理复杂逻辑时幻觉更容易发生。应对方法：将复杂逻辑拆分成简单步骤。要求 AI 详细解释逻辑。对每一步进行单独验证。

### 调试代码

调试过程中需要特别注意幻觉。应对方法：提供完整的错误信息。描述你已知的排查结果。让 AI 基于已知信息分析。

## 建立信任边界

### 信任分级

对 AI 生成的内容建立信任分级：高信任：简单的代码片段、已知的模式。中信任：常见的 API 调用、标准的业务逻辑。低信任：复杂的算法、不熟悉的领域、边界情况处理。

### 验证策略

对不同信任级别采用不同的验证策略：高信任：快速检查后采用。中信任：运行测试后采用。低信任：详细测试 + 人工审核后采用。

### 持续校准

随着使用经验的积累，你会越来越了解 AI 的能力和局限性。持续校准你的信任边界，调整验证策略。

## 幻觉的价值

虽然幻觉是问题，但也要看到它的价值。AI 的错误有时会启发你思考新的解决方案。幻觉也可以作为讨论的起点，引发更深入的思考。

关键是保持批判性思维，不盲目接受 AI 的输出，也不因为遇到幻觉而完全否定 AI 的价值。
