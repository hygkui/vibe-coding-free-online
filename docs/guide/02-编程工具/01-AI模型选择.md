# AI 模型选择

## 主流 AI 编程模型介绍

在 Vibe Coding 中，选择合适的 AI 模型是成功的关键一步。不同的模型有不同的特点和适用场景，了解它们可以帮助你做出更好的选择。

### OpenAI 系列模型

OpenAI 是 AI 编程领域的领导者，2025 年发布了多款强大的编程模型。

**GPT-5** 是 2025 年 8 月发布的旗舰模型，作为 GPT-4 的继任者，采用多模型智能路由系统，支持文本、图像、音频和视频的多模态处理。GPT-5 在推理能力和编程性能上都有显著提升，提供 gpt-5、gpt-5-mini、gpt-5-nano 三种规格。

**o3 和 o4-mini** 于 2025 年 4 月发布，是专注于推理的独立模型系列：
- **o3**：高级推理模型，专为复杂问题求解设计
- **o4-mini**：高性价比推理模型，适合大批量处理场景

**GPT-5-Codex** 是专门的编程模型，支持动态思维链，编程能力更强。

使用 OpenAI 模型的方式主要有两种：一是通过 ChatGPT 网页版直接对话，适合快速上手和简单任务；二是通过 API 集成到开发工具中，适合专业开发者和高频使用者。

### Claude 系列模型

Claude 是 Anthropic 公司开发的 AI 模型，在编程方面表现出色，被认为是代码生成领域的领先者。

**Claude 4.5 系列**（2025 年 9-11 月发布）是最新一代模型：

- **Claude Opus 4.5**（2025 年 11 月）：Anthropic 最智能高效的模型，专为编程、智能体和计算机操作设计。支持「无限对话」功能消除上下文窗口限制，定价 $5/百万输入 token，$25/百万输出 token
- **Claude Sonnet 4.5**（2025 年 9 月）：编程和智能体的高性能模型，在 SWE-bench Verified 和 OSWorld 基准测试中表现优异，能够在复杂多步骤任务上保持 30+ 小时的专注。定价 $3/百万输入 token，$15/百万输出 token
- **Claude Haiku 4.5**（2025 年 10 月）：轻量级快速模型，适合简单任务和需要快速反馈的场景

**Claude 4 系列**（2025 年 5 月发布）：Claude Opus 4 可独立运行 7 小时完成复杂任务，Claude Sonnet 4 在编程基准测试中表现出色。

所有 Claude 4.x 模型都支持 200K 上下文窗口和长文档处理。Claude 的特点是生成的代码可读性强、结构清晰，对话风格友好详细，适合初学者。

### Google Gemini 系列

Google 在 2025 年推出了 Gemini 3 系列，表现亮眼。

**Gemini 3 Flash**（2025 年 12 月）：主打「前沿智能，极致速度」，比 Gemini 2.5 Pro 快 3 倍且性能更强。在 GPQA Diamond（博士级科学推理）达到 90.4%，MMMU Pro（多模态理解）达到 81.2%。支持「快速」「思考」「专业」三种模式动态调整推理深度。已成为 Gemini 消费端应用和 Google 搜索 AI 响应的默认模型。

**Gemini 3 Pro**：高端推理模型，适合复杂问题和智能体工作流，是需要顶级推理能力场景的首选。

Gemini 系列支持文本、图像、视频、音频和 PDF 的多模态处理，特别适合涉及 Google 生态系统的项目。

### 国产大模型

国产模型在 2025 年快速发展，对中文支持更好，使用门槛更低，性价比高。

**DeepSeek**：深度求索推出的模型，在编程和推理任务上表现优异，API 价格极具竞争力，开源版本可本地部署。DeepSeek-V3 和 DeepSeek-R1 在多项基准测试中达到国际一流水平。

**Qwen（通义千问）**：阿里云推出的大模型，Qwen 2.5 系列在代码生成、数学推理上表现出色，提供多种规格（72B、32B、14B、7B 等），支持本地部署。

**Doubao（豆包）**：字节跳动推出的大模型，响应速度快，中文理解能力强，与 Coze 平台深度集成，适合构建智能体应用。

**GLM（智谱清言）**：智谱 AI 推出的 GLM-4 系列，在中文理解和生成上表现优秀，提供开源版本 ChatGLM，适合私有化部署。

**MiniMax**：专注于多模态的国产模型，在语音合成和视频生成上有独特优势，适合需要多模态能力的应用场景。

**Kimi（月之暗面）**：以超长上下文窗口著称（支持 200 万字），特别适合处理长文档和大型代码库分析。

### 开源模型

**Meta Llama 3**：开源模型中的佼佼者，可本地部署，适合对隐私有要求或需要定制化的场景。Llama 3.1 405B 是目前最强的开源模型之一。

## 如何选择合适的模型

选择 AI 模型需要考虑多个因素。

**任务复杂度**是首要考虑因素。简单的任务如代码补全、语法转换等，中等规模的模型就足够了。复杂的任务如系统设计、算法优化等，需要更强大的模型。

**预算**也是重要因素。免费模型如 ChatGPT 免费版、Claude 免费版可以满足基本需求，但如果高频使用，订阅付费版本更划算。

**响应速度**影响使用体验。某些场景下需要快速反馈，这时候响应速度更快的模型更有优势。

**中文支持**对中文用户很重要。不同模型对中文的理解能力有差异，选择中文支持好的模型可以减少沟通成本。

### 场景化推荐

根据不同使用场景，我们给出以下推荐：

**学习和练习阶段**：推荐使用 ChatGPT 免费版、Claude 免费版或国产模型（豆包、Kimi 等免费额度充足）。这个阶段任务简单，使用频率不高，免费版完全够用。

**日常开发阶段**：推荐使用 ChatGPT Plus、Claude Pro 或 DeepSeek API。这些版本速度快、限制少，适合日常编程工作。DeepSeek 性价比极高。

**专业开发阶段**：推荐使用 Claude Sonnet 4.5、GPT-5 或 Gemini 3 Pro。这个阶段的代码质量要求高，需要最强大的模型支持。

**企业应用阶段**：推荐使用 Claude Opus 4.5 或 GPT-5。这些版本提供更好的安全性和稳定性，适合企业级应用。国内企业可考虑 Qwen、GLM 等支持私有化部署的模型。

**长文档/大代码库**：推荐使用 Kimi（200 万字上下文）或 Claude 4.x（200K 上下文）。

## 模型使用技巧

了解模型的特点后，我们来学习一些使用技巧。

### 提示词优化

同一个任务，用不同的提示词可能得到截然不同的结果。好的提示词应该清晰、具体、有条理。

不要使用模糊的描述。比如"写一个好的登录功能"，这样的描述太笼统。应该具体说明需要哪些字段、有什么验证规则、错误如何处理等。

分解复杂任务。把大任务拆分成小任务，逐个解决。比如不要让 AI 一次性写完整个应用，而是先完成数据库设计，再完成前端界面，最后完成业务逻辑。

提供上下文。在请求代码时，告诉 AI 你使用的技术栈、代码风格要求、性能考虑等，这些都会影响 AI 的输出。

### 处理模型局限性

AI 模型不是完美的，了解它们的局限性可以帮助你更好地使用它们。

模型可能会生成过时或不安全的代码。使用前务必检查代码的依赖版本、安全漏洞等问题。

模型对复杂系统的理解有限。如果你需要设计大型系统，建议分模块让 AI 处理，然后人工整合。

模型可能会产生幻觉，就是生成看似合理但实际错误的代码。一定要验证 AI 输出的代码，特别是涉及业务逻辑的部分。

### 成本控制

使用付费模型时，注意控制成本。

减少不必要的对话。在开始对话前，明确自己的问题，避免漫无边际的聊天。

使用缓存。对重复的问题，可以保存之前的回答，避免重复付费。

选择合适的模型。不是所有任务都需要最强大的模型，简单任务用简单模型可以节省成本。
